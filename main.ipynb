{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d82c65f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run C:/Users/Hamid/SincNet_parkinson/data_io.ipynb\n",
    "%run C:/Users/Hamid/SincNet_parkinson/dnn_models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df320f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TEST/Vito L(P)/B1VLIAT OP47M100220171314.wav : 1'\n",
      " 'TEST/Vito L(P)/B2VLIAT OP47M100220171316.wav : 1'\n",
      " 'TEST/Roberto L/B1RLOABREE42M240120171942.wav : 1'\n",
      " 'TEST/Roberto L/B2RLOABREE42M240120171944.wav : 1'\n",
      " 'TEST/GILDA C/B1GCIALSDA52F170320171124.wav : 0'\n",
      " 'TEST/GILDA C/B2GCIALSDA52F170320171125.wav : 0'\n",
      " 'TEST/Luigi B/B1lbuairgo52M1606161810.wav : 1'\n",
      " 'TEST/Luigi B/B2lbuairgo52M1606161811.wav : 1'\n",
      " 'TEST/GIOVANNI B/B1GBIAORVI48M230320171233.wav : 0'\n",
      " 'TEST/GIOVANNI B/B2GBIAORVI48M230320171234.wav : 0'\n",
      " 'TEST/Domenico C/B1cdaopmoe67M2605161902.wav : 1'\n",
      " 'TEST/Domenico C/B2cdaopmoe67M2605161904.wav : 1'\n",
      " 'TEST/PORCELLI A/B1APNOTROC49M230320170926.wav : 0'\n",
      " 'TEST/PORCELLI A/B2APNOTROC49M230320170927.wav : 0'\n",
      " 'TEST/ANTONIO C/B1ACNUTCOC40M230320171121.wav : 0'\n",
      " 'TEST/ANTONIO C/B2ACNUTCOC40M230320171123.wav : 0'\n",
      " 'TEST/Leonarda L/B1lloeroun56F2605161922.wav : 1'\n",
      " 'TEST/Leonarda L/B2lloeroun56F2605161923.wav : 1'\n",
      " 'TEST/Vito S(2)/B1vsiptioz46M1606161659.wav : 1'\n",
      " 'TEST/Vito S(2)/B2vsiptioz46M1606161701.wav : 1'\n",
      " 'TEST/Giovanni N/B1GNIEOGVL47M100220171213.wav : 1'\n",
      " 'TEST/Giovanni N/B2GNIEOGVL47M100220171214.wav : 1'\n",
      " 'TRAIN/Nicola M/B1NMIICNOO52M100220171134.wav : 1'\n",
      " 'TRAIN/Antonia G/B1AGNUTGOL52F100220171041.wav : 1'\n",
      " 'TRAIN/Antonia G/B2AGNUTGOL52F100220171045.wav : 1'\n",
      " 'TRAIN/Giustina M/B1GMIAUSST39F100220171156.wav : 1'\n",
      " 'TRAIN/Anna B/B1ABNINSAC46F240120171753.wav : 1'\n",
      " 'TRAIN/Anna B/B2ABNINSAC46F240120171755.wav : 1'\n",
      " 'TRAIN/Roberto R/B1RROIBVEI49M240120171859.wav : 1'\n",
      " 'TRAIN/Roberto R/B2RROIBVEI49M240120171902.wav : 1'\n",
      " 'TRAIN/LUIGI P/B1LPUUITGI41M230320171109.wav : 0'\n",
      " 'TRAIN/LUIGI P/B2LPUUITGI41M230320171110.wav : 0'\n",
      " 'TRAIN/GIOVANNA G/B1GGIAORVG47F300320171207.wav : 0'\n",
      " 'TRAIN/GIOVANNA G/B2GGIAORVG47F300320171210.wav : 0'\n",
      " 'TRAIN/Mario B/B1MBAUROIN45M100220171003.wav : 1'\n",
      " 'TRAIN/Mario B/B2MBAUROIN45M100220171006.wav : 1'\n",
      " 'TRAIN/Vito L/B1VLIATFOO55M300320171237.wav : 0'\n",
      " 'TRAIN/Vito L/B2VLIATFOO55M300320171238.wav : 0'\n",
      " 'TRAIN/ANGELA C/B1ACNAGRER49F210320170916.wav : 0'\n",
      " 'TRAIN/ANGELA C/B2ACNAGRER49F210320170919.wav : 0'\n",
      " 'TRAIN/GRAZIA G/B1GGRIAUZL45F020420171817.wav : 0'\n",
      " 'TRAIN/GRAZIA G/B2GGRIAUZL45F020420171820.wav : 0'\n",
      " 'TRAIN/ANTONIETTA P/B1APNITNOT56F230320170847.wav : 0'\n",
      " 'TRAIN/ANTONIETTA P/B2APNITNOT56F230320170849.wav : 0'\n",
      " 'TRAIN/LISCO G/B1GLIIUSSC57M210320171050.wav : 0'\n",
      " 'TRAIN/LISCO G/B2GLIIUSSC57M210320171051.wav : 0'\n",
      " 'TRAIN/AGNESE P/B1APGANRET55F170320171104.wav : 0'\n",
      " 'TRAIN/AGNESE P/B2APGANRET55F170320171105.wav : 0'\n",
      " 'TRAIN/SUMMO L/B1LSUUIMGM48F230320171049.wav : 0'\n",
      " 'TRAIN/SUMMO L/B2LSUUIMGM48F230320171050.wav : 0'\n",
      " 'TRAIN/Giulia P/B1GPIUUGLL63F100220171020.wav : 1'\n",
      " 'TRAIN/Giulia P/B2GPIUUGLL63F100220171021.wav : 1'\n",
      " 'TRAIN/NICOLA P/B1NPIICEOR42M020420171805.wav : 0'\n",
      " 'TRAIN/NICOLA P/B2NPIICEOR42M020420171807.wav : 0'\n",
      " 'TRAIN/TERESA M/B1TMEIRAEC54F230320171150.wav : 0'\n",
      " 'TRAIN/TERESA M/B2TMEIRAEC54F230320171152.wav : 0'\n",
      " 'TRAIN/Michele C/B1MCIICLHL46M240120171825.wav : 1'\n",
      " 'TRAIN/Michele C/B2MCIICLHL46M240120171827.wav : 1'\n",
      " 'TRAIN/VITO A/B1VAILTFOO49M230320171029.wav : 0'\n",
      " 'TRAIN/VITO A/B2VAILTFOO49M230320171030.wav : 0'\n",
      " 'TRAIN/Ugo B/B1ubguot_t40M1606161755.wav : 1'\n",
      " 'TRAIN/Ugo B/B2ubguot_t40M1606161756.wav : 1'\n",
      " 'TRAIN/MICHELE G/B1MGIACTHT49M210320170848.wav : 0'\n",
      " 'TRAIN/MICHELE G/B2MGIACTHT49M210320170850.wav : 0'\n",
      " 'TRAIN/Giulia L/B1GLIAUDLO50F100220171257.wav : 1'\n",
      " 'TRAIN/Giulia L/B2GLIAUDLO50F100220171259.wav : 1'\n",
      " 'TRAIN/Nicola S/B1sncihcio44M1606161717.wav : 1'\n",
      " 'TRAIN/Nicola S/B2sncihcio44M1606161718.wav : 1'\n",
      " 'TRAIN/Lucia R/B1rlouscsi77F2605161820.wav : 1'\n",
      " 'TRAIN/Lucia R/B2rlouscsi77F2605161822.wav : 1'\n",
      " 'TRAIN/Saverio S/B1ssacvhei61M1606161740.wav : 1'\n",
      " 'TRAIN/Saverio S/B2ssacvhei61M1606161741.wav : 1'\n",
      " 'TRAIN/LEONARDA F/B1LFEIOONR57F210320171120.wav : 0'\n",
      " 'TRAIN/LEONARDA F/B2LFEIOONR57F210320171124.wav : 0'\n",
      " 'TRAIN/Nicolò C/B1NCIICAOC52M100220171237.wav : 1'\n",
      " 'TRAIN/Roberto R(2)/B1rriovbie49M2605161841.wav : 1'\n",
      " 'TRAIN/Roberto R(2)/B2rriovbie49M2605161842.wav : 1'\n",
      " 'TRAIN/Giovanni M/B1GMIAOSVI44M100220170942.wav : 1'\n",
      " 'TRAIN/Giovanni M/B2GMIAOSVI44M100220170944.wav : 1'\n",
      " 'TRAIN/Vito S/B1VSIOTLOP47M100220171328.wav : 1'\n",
      " 'TRAIN/Vito S/B2VSIOTLOP47M100220171330.wav : 1'\n",
      " 'TRAIN/BRIGIDA C/B1BCRAISGS48F210320171002.wav : 0'\n",
      " 'TRAIN/BRIGIDA C/B2BCRAISGS48F210320171004.wav : 0'\n",
      " 'TRAIN/Felicetta C/B1cfaerlei54F2605161738.wav : 1'\n",
      " 'TRAIN/Felicetta C/B2cfaerlei54F2605161740.wav : 1'\n",
      " 'TRAIN/ANGELA G/B1AGNIGNEE54F230320171018.wav : 0'\n",
      " 'TRAIN/ANGELA G/B2AGNIGNEE54F230320171019.wav : 0'\n",
      " 'TRAIN/MARIACRISTINA P/B1MPAERRIR56F300320171143.wav : 0'\n",
      " 'TRAIN/MARIACRISTINA P/B2MPAERRIR56F300320171145.wav : 0'\n",
      " 'TRAIN/Daria L/B1DLAARCII37F100220171111.wav : 1']\n",
      "['TEST/ANGELA G/B1AGNIGNEE54F230320171018.wav', 'TEST/ANGELA G/B2AGNIGNEE54F230320171019.wav', 'TEST/ANTONIETTA P/B1APNITNOT56F230320170847.wav', 'TEST/ANTONIETTA P/B2APNITNOT56F230320170849.wav', 'TEST/Daniele R/B1LBULCAAS94M100120171057.wav', 'TEST/Daniele R/B2LBULCAAS94M100120171057.wav', 'TEST/Daria L/B1DLAARCII37F100220171111.wav', 'TEST/Gennaro T/B1LBULCAAS94M100120171064.wav', 'TEST/Gennaro T/B2LBULCAAS94M100120171064.wav', 'TEST/GILDA C/B1GCIALSDA52F170320171124.wav', 'TEST/GILDA C/B2GCIALSDA52F170320171125.wav', 'TEST/Giovanni N/B1GNIEOGVL47M100220171213.wav', 'TEST/Giovanni N/B2GNIEOGVL47M100220171214.wav', 'TEST/GRAZIA G/B1GGRIAUZL45F020420171817.wav', 'TEST/GRAZIA G/B2GGRIAUZL45F020420171820.wav', 'TEST/Lucia R/B1rlouscsi77F2605161820.wav', 'TEST/Lucia R/B2rlouscsi77F2605161822.wav', 'TEST/Luigi B/B1lbuairgo52M1606161810.wav', 'TEST/Luigi B/B2lbuairgo52M1606161811.wav', 'TEST/Mario B/B1MBAUROIN45M100220171003.wav', 'TEST/Mario B/B2MBAUROIN45M100220171006.wav', 'TEST/Nicola M/B1NMIICNOO52M100220171134.wav', 'TEST/Nicolò C/B1NCIICAOC52M100220171237.wav', 'TEST/SUMMO L/B1LSUUIMGM48F230320171049.wav', 'TEST/SUMMO L/B2LSUUIMGM48F230320171050.wav', 'TEST/Ugo B/B1ubguot_t40M1606161755.wav', 'TEST/Ugo B/B2ubguot_t40M1606161756.wav']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'TRAIN/Davide S/B1LBULCAAS94M100120171036.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 225\u001b[0m\n\u001b[0;32m    222\u001b[0m err_sum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_batches):\n\u001b[1;32m--> 225\u001b[0m   [inp,lab]\u001b[38;5;241m=\u001b[39mcreate_batches_rnd(batch_size,data_folder,wav_lst_tr,snt_tr,wlen,lab_dict,\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m    226\u001b[0m   pout\u001b[38;5;241m=\u001b[39mDNN2_net(DNN1_net(CNN_net(inp)))\n\u001b[0;32m    228\u001b[0m   pred\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mmax(pout,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn[8], line 55\u001b[0m, in \u001b[0;36mcreate_batches_rnd\u001b[1;34m(batch_size, data_folder, wav_lst, N_snt, wlen, lab_dict, fact_amp)\u001b[0m\n\u001b[0;32m     52\u001b[0m    signal \u001b[38;5;241m=\u001b[39m signal[:,\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     54\u001b[0m  sig_batch[i,:]\u001b[38;5;241m=\u001b[39msignal[snt_beg:snt_end]\u001b[38;5;241m*\u001b[39mrand_amp_arr[i]\n\u001b[1;32m---> 55\u001b[0m  lab_batch[i]\u001b[38;5;241m=\u001b[39mlab_dict[wav_lst[snt_id_arr[i]]]\n\u001b[0;32m     57\u001b[0m inp\u001b[38;5;241m=\u001b[39mVariable(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(sig_batch)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mcuda()\u001b[38;5;241m.\u001b[39mcontiguous())\n\u001b[0;32m     58\u001b[0m lab\u001b[38;5;241m=\u001b[39mVariable(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(lab_batch)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mcuda()\u001b[38;5;241m.\u001b[39mcontiguous())\n",
      "\u001b[1;31mKeyError\u001b[0m: 'TRAIN/Davide S/B1LBULCAAS94M100120171036.wav'"
     ]
    }
   ],
   "source": [
    "# speaker_id.py\n",
    "# Mirco Ravanelli \n",
    "# Mila - University of Montreal \n",
    "\n",
    "# July 2018\n",
    "\n",
    "# Description: \n",
    "# This code performs a speaker_id experiments with SincNet.\n",
    " \n",
    "# How to run it:\n",
    "# python speaker_id.py --cfg=cfg/SincNet_TIMIT.cfg\n",
    "\n",
    "import os\n",
    "#import scipy.io.wavfile\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def create_batches_rnd(batch_size,data_folder,wav_lst,N_snt,wlen,lab_dict,fact_amp):\n",
    "    \n",
    " # Initialization of the minibatch (batch_size,[0=>x_t,1=>x_t+N,1=>random_samp])\n",
    " sig_batch=np.zeros([batch_size,wlen])\n",
    " lab_batch=np.zeros(batch_size)\n",
    "  \n",
    " snt_id_arr=np.random.randint(N_snt, size=batch_size)\n",
    " \n",
    " rand_amp_arr = np.random.uniform(1.0-fact_amp,1+fact_amp,batch_size)\n",
    "\n",
    " for i in range(batch_size):\n",
    "     \n",
    "  # select a random sentence from the list \n",
    "  #[fs,signal]=scipy.io.wavfile.read(data_folder+wav_lst[snt_id_arr[i]])\n",
    "  #signal=signal.astype(float)/32768\n",
    "\n",
    "  [signal, fs] = sf.read(data_folder+wav_lst[snt_id_arr[i]])\n",
    "\n",
    "  # accesing to a random chunk\n",
    "  snt_len=signal.shape[0]\n",
    "  snt_beg=np.random.randint(snt_len-wlen-1) #randint(0, snt_len-2*wlen-1)\n",
    "  snt_end=snt_beg+wlen\n",
    "\n",
    "  channels = len(signal.shape)\n",
    "  if channels == 2:\n",
    "    print('WARNING: stereo to mono: '+data_folder+wav_lst[snt_id_arr[i]])\n",
    "    signal = signal[:,0]\n",
    "  \n",
    "  sig_batch[i,:]=signal[snt_beg:snt_end]*rand_amp_arr[i]\n",
    "  lab_batch[i]=lab_dict[wav_lst[snt_id_arr[i]]]\n",
    "  \n",
    " inp=Variable(torch.from_numpy(sig_batch).float().cuda().contiguous())\n",
    " lab=Variable(torch.from_numpy(lab_batch).float().cuda().contiguous())\n",
    "  \n",
    " return inp,lab  \n",
    "\n",
    "\n",
    "\n",
    "# Reading cfg file\n",
    "options=read_conf()\n",
    "\n",
    "# Accessing parameters from the options dictionary\n",
    "tr_lst = options['tr_lst']\n",
    "te_lst = options['te_lst']\n",
    "pt_file = options['pt_file']\n",
    "class_dict_file = options['lab_dict']\n",
    "data_folder = options['data_folder'] + '/'\n",
    "output_folder=options['output_folder']\n",
    "\n",
    "# [windowing]\n",
    "fs = int(options['fs'])\n",
    "cw_len = int(options['cw_len'])\n",
    "cw_shift = int(options['cw_shift'])\n",
    "\n",
    "# [cnn]\n",
    "cnn_N_filt = list(map(int, options['cnn_N_filt'].split(',')))\n",
    "cnn_len_filt = list(map(int, options['cnn_len_filt'].split(',')))\n",
    "cnn_max_pool_len = list(map(int, options['cnn_max_pool_len'].split(',')))\n",
    "cnn_use_laynorm_inp = str_to_bool(options['cnn_use_laynorm_inp'])\n",
    "cnn_use_batchnorm_inp = str_to_bool(options['cnn_use_batchnorm_inp'])\n",
    "cnn_use_laynorm = list(map(str_to_bool, options['cnn_use_laynorm'].split(',')))\n",
    "cnn_use_batchnorm = list(map(str_to_bool, options['cnn_use_batchnorm'].split(',')))\n",
    "cnn_act = list(map(str, options['cnn_act'].split(',')))\n",
    "cnn_drop = list(map(float, options['cnn_drop'].split(',')))\n",
    "\n",
    "# [dnn]\n",
    "fc_lay = list(map(int, options['fc_lay'].split(',')))\n",
    "fc_drop = list(map(float, options['fc_drop'].split(',')))\n",
    "fc_use_laynorm_inp = str_to_bool(options['fc_use_laynorm_inp'])\n",
    "fc_use_batchnorm_inp = str_to_bool(options['fc_use_batchnorm_inp'])\n",
    "fc_use_batchnorm = list(map(str_to_bool, options['fc_use_batchnorm'].split(',')))\n",
    "fc_use_laynorm = list(map(str_to_bool, options['fc_use_laynorm'].split(',')))\n",
    "fc_act = list(map(str, options['fc_act'].split(',')))\n",
    "\n",
    "# [class]\n",
    "class_lay = list(map(int, options['class_lay'].split(',')))\n",
    "class_drop = list(map(float, options['class_drop'].split(',')))\n",
    "class_use_laynorm_inp = str_to_bool(options['class_use_laynorm_inp'])\n",
    "class_use_batchnorm_inp = str_to_bool(options['class_use_batchnorm_inp'])\n",
    "class_use_batchnorm = list(map(str_to_bool, options['class_use_batchnorm'].split(',')))\n",
    "class_use_laynorm = list(map(str_to_bool, options['class_use_laynorm'].split(',')))\n",
    "class_act = list(map(str, options['class_act'].split(',')))\n",
    "f\n",
    "# [optimization]\n",
    "lr = float(options['lr'])\n",
    "batch_size = int(options['batch_size'])\n",
    "N_epochs = 17\n",
    "N_batches = 200\n",
    "N_eval_epoch = int(options['N_eval_epoch'])\n",
    "seed = int(options['seed'])\n",
    "\n",
    "# training list\n",
    "wav_lst_tr = ReadList(tr_lst)\n",
    "snt_tr = len(wav_lst_tr)\n",
    "\n",
    "# test list\n",
    "wav_lst_te = ReadList(te_lst)\n",
    "snt_te = len(wav_lst_te)\n",
    "\n",
    "\n",
    "# Folder creation\n",
    "try:\n",
    "    os.stat(output_folder)\n",
    "except:\n",
    "    os.mkdir(output_folder) \n",
    "    \n",
    "    \n",
    "# setting seed\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# loss function\n",
    "cost = nn.NLLLoss()\n",
    "\n",
    "  \n",
    "# Converting context and shift in samples\n",
    "wlen=int(fs*cw_len/1000.00)\n",
    "wshift=int(fs*cw_shift/1000.00)\n",
    "\n",
    "# Batch_dev\n",
    "Batch_dev=128\n",
    "\n",
    "\n",
    "# Feature extractor CNN\n",
    "CNN_arch = {'input_dim': wlen,\n",
    "          'fs': fs,\n",
    "          'cnn_N_filt': cnn_N_filt,\n",
    "          'cnn_len_filt': cnn_len_filt,\n",
    "          'cnn_max_pool_len':cnn_max_pool_len,\n",
    "          'cnn_use_laynorm_inp': cnn_use_laynorm_inp,\n",
    "          'cnn_use_batchnorm_inp': cnn_use_batchnorm_inp,\n",
    "          'cnn_use_laynorm':cnn_use_laynorm,\n",
    "          'cnn_use_batchnorm':cnn_use_batchnorm,\n",
    "          'cnn_act': cnn_act,\n",
    "          'cnn_drop':cnn_drop,          \n",
    "          }\n",
    "\n",
    "CNN_net=SincNet(CNN_arch)\n",
    "CNN_net.cuda()\n",
    "# Loading label dictionary\n",
    "loaded_data = np.load(class_dict_file, allow_pickle=True)\n",
    "\n",
    "# Convert the loaded data into a dictionary\n",
    "lab_dict = {item.split(\" : \")[0]: int(item.split(\" : \")[1]) for item in loaded_data}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "DNN1_arch = {'input_dim': CNN_net.out_dim,\n",
    "          'fc_lay': fc_lay,\n",
    "          'fc_drop': fc_drop, \n",
    "          'fc_use_batchnorm': fc_use_batchnorm,\n",
    "          'fc_use_laynorm': fc_use_laynorm,\n",
    "          'fc_use_laynorm_inp': fc_use_laynorm_inp,\n",
    "          'fc_use_batchnorm_inp':fc_use_batchnorm_inp,\n",
    "          'fc_act': fc_act,\n",
    "          }\n",
    "\n",
    "DNN1_net=MLP(DNN1_arch)\n",
    "DNN1_net.cuda()\n",
    "\n",
    "\n",
    "DNN2_arch = {'input_dim':fc_lay[-1] ,\n",
    "          'fc_lay': class_lay,\n",
    "          'fc_drop': class_drop, \n",
    "          'fc_use_batchnorm': class_use_batchnorm,\n",
    "          'fc_use_laynorm': class_use_laynorm,\n",
    "          'fc_use_laynorm_inp': class_use_laynorm_inp,\n",
    "          'fc_use_batchnorm_inp':class_use_batchnorm_inp,\n",
    "          'fc_act': class_act,\n",
    "          }\n",
    "\n",
    "DNN2_net=MLP(DNN2_arch)\n",
    "DNN2_net.cuda()\n",
    "\n",
    "if pt_file!='none':\n",
    "   checkpoint_load = torch.load(pt_file)\n",
    "   CNN_net.load_state_dict(checkpoint_load['CNN_model_par'])\n",
    "   DNN1_net.load_state_dict(checkpoint_load['DNN1_model_par'])\n",
    "   DNN2_net.load_state_dict(checkpoint_load['DNN2_model_par'])\n",
    "\n",
    "\n",
    "\n",
    "optimizer_CNN = optim.RMSprop(CNN_net.parameters(), lr=lr,alpha=0.95, eps=1e-8) \n",
    "optimizer_DNN1 = optim.RMSprop(DNN1_net.parameters(), lr=lr,alpha=0.95, eps=1e-8) \n",
    "optimizer_DNN2 = optim.RMSprop(DNN2_net.parameters(), lr=lr,alpha=0.95, eps=1e-8) \n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(N_epochs):\n",
    "\n",
    "  test_flag=0\n",
    "  CNN_net.train()\n",
    "  DNN1_net.train()\n",
    "  DNN2_net.train()\n",
    " \n",
    "  loss_sum=0\n",
    "  err_sum=0\n",
    "  for i in range(N_batches):\n",
    "\n",
    "    [inp,lab]=create_batches_rnd(batch_size,data_folder,wav_lst_tr,snt_tr,wlen,lab_dict,0.2)\n",
    "    pout=DNN2_net(DNN1_net(CNN_net(inp)))\n",
    "    \n",
    "    pred=torch.max(pout,dim=1)[1]\n",
    "    loss = cost(pout, lab.long())\n",
    "    err = torch.mean((pred!=lab.long()).float())\n",
    "    \n",
    "   \n",
    "    optimizer_CNN.zero_grad()\n",
    "    optimizer_DNN1.zero_grad() \n",
    "    optimizer_DNN2.zero_grad() \n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer_CNN.step()\n",
    "    optimizer_DNN1.step()\n",
    "    optimizer_DNN2.step()\n",
    "    \n",
    "    loss_sum=loss_sum+loss.detach()\n",
    "    err_sum=err_sum+err.detach()\n",
    " \n",
    "\n",
    "  loss_tot=loss_sum/N_batches\n",
    "  err_tot=err_sum/N_batches\n",
    "  \n",
    " \n",
    "   \n",
    "   \n",
    "# Full Validation  new  \n",
    "  if epoch%N_eval_epoch==0:\n",
    "      \n",
    "   CNN_net.eval()\n",
    "   DNN1_net.eval()\n",
    "   DNN2_net.eval()\n",
    "   test_flag=1 \n",
    "   loss_sum=0\n",
    "   err_sum=0\n",
    "   err_sum_snt=0\n",
    "   \n",
    "   with torch.no_grad():  \n",
    "    for i in range(snt_te):\n",
    "     #[fs,signal]=scipy.io.wavfile.read(data_folder+wav_lst_te[i])\n",
    "     #signal=signal.astype(float)/32768\n",
    "\n",
    "     [signal, fs] = sf.read(data_folder+wav_lst_te[i])\n",
    "\n",
    "     signal=torch.from_numpy(signal).float().cuda().contiguous()\n",
    "     lab_batch=lab_dict[wav_lst_te[i]]\n",
    "    \n",
    "     # split signals into chunks\n",
    "     beg_samp=0\n",
    "     end_samp=wlen\n",
    "     \n",
    "     N_fr=int((signal.shape[0]-wlen)/(wshift))\n",
    "\n",
    "\n",
    "     sig_arr=torch.zeros([Batch_dev,wlen]).float().cuda().contiguous()\n",
    "     lab= Variable((torch.zeros(N_fr+1)+lab_batch).cuda().contiguous().long())\n",
    "     pout=Variable(torch.zeros(N_fr+1,class_lay[-1]).cuda().float().contiguous())\n",
    "     count_fr=0\n",
    "     count_fr_tot=0\n",
    "     while end_samp<signal.shape[0]:\n",
    "         sig_arr[count_fr,:]=signal[beg_samp:end_samp]\n",
    "         beg_samp=beg_samp+wshift\n",
    "         end_samp=beg_samp+wlen\n",
    "         count_fr=count_fr+1\n",
    "         count_fr_tot=count_fr_tot+1\n",
    "         if count_fr==Batch_dev:\n",
    "             inp=Variable(sig_arr)\n",
    "             pout[count_fr_tot-Batch_dev:count_fr_tot,:]=DNN2_net(DNN1_net(CNN_net(inp)))\n",
    "             count_fr=0\n",
    "             sig_arr=torch.zeros([Batch_dev,wlen]).float().cuda().contiguous()\n",
    "   \n",
    "     if count_fr>0:\n",
    "      inp=Variable(sig_arr[0:count_fr])\n",
    "      pout[count_fr_tot-count_fr:count_fr_tot,:]=DNN2_net(DNN1_net(CNN_net(inp)))\n",
    "\n",
    "    \n",
    "     pred=torch.max(pout,dim=1)[1]\n",
    "     loss = cost(pout, lab.long())\n",
    "     err = torch.mean((pred!=lab.long()).float())\n",
    "     print('pred: ',pred)\n",
    "     [val,best_class]=torch.max(torch.sum(pout,dim=0),0)\n",
    "     err_sum_snt=err_sum_snt+(best_class!=lab[0]).float()\n",
    "    \n",
    "    \n",
    "     loss_sum=loss_sum+loss.detach()\n",
    "     err_sum=err_sum+err.detach()\n",
    "    \n",
    "    err_tot_dev_snt=err_sum_snt/snt_te\n",
    "    loss_tot_dev=loss_sum/snt_te \n",
    "    err_tot_dev=err_sum/snt_te\n",
    "\n",
    "    \n",
    "   print(\"epoch %i, loss_tr=%f err_tr=%f loss_te=%f err_te=%f err_te_snt=%f\" % (epoch, loss_tot,err_tot,loss_tot_dev,err_tot_dev,err_tot_dev_snt))\n",
    "  \n",
    "   with open(output_folder+\"/res.res\", \"a\") as res_file:\n",
    "    res_file.write(\"epoch %i, loss_tr=%f err_tr=%f loss_te=%f err_te=%f err_te_snt=%f\\n\" % (epoch, loss_tot,err_tot,loss_tot_dev,err_tot_dev,err_tot_dev_snt))   \n",
    "\n",
    "   checkpoint={'CNN_model_par': CNN_net.state_dict(),\n",
    "               'DNN1_model_par': DNN1_net.state_dict(),\n",
    "               'DNN2_model_par': DNN2_net.state_dict(),\n",
    "               }\n",
    "   torch.save(checkpoint,output_folder+'/model_raw.pkl')\n",
    "  \n",
    "  else:\n",
    "   print(\"epoch %i, loss_tr=%f err_tr=%f\" % (epoch, loss_tot,err_tot))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f7003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a19e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29915b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
