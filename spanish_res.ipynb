{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d82c65f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run C:/Users/Hamid/SincNet_parkinson/data_io.ipynb\n",
    "%run C:/Users/Hamid/SincNet_parkinson/dnn_models.ipynb\n",
    "torch.cuda.empty_cache()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df320f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss_tr=0.648753 accuracy=0.665234 loss_val=0.567231 accuracy_val=0.666667\n",
      "epoch 1, loss_tr=0.397985 accuracy=0.824102 loss_val=0.353968 accuracy_val=0.833333\n",
      "epoch 2, loss_tr=0.313440 accuracy=0.866836 loss_val=0.254238 accuracy_val=0.833333\n",
      "epoch 3, loss_tr=0.255764 accuracy=0.893242 loss_val=0.289369 accuracy_val=0.833333\n",
      "epoch 4, loss_tr=0.218264 accuracy=0.908242 loss_val=0.287343 accuracy_val=0.333333\n",
      "epoch 5, loss_tr=0.193294 accuracy=0.920859 loss_val=0.226344 accuracy_val=0.500000\n",
      "epoch 6, loss_tr=0.170740 accuracy=0.926875 loss_val=0.194146 accuracy_val=0.833333\n",
      "epoch 7, loss_tr=0.155542 accuracy=0.936289 loss_val=0.095499 accuracy_val=0.833333\n",
      "epoch 8, loss_tr=0.140959 accuracy=0.940937 loss_val=0.172964 accuracy_val=0.833333\n",
      "epoch 9, loss_tr=0.128837 accuracy=0.947422 loss_val=0.131498 accuracy_val=0.833333\n",
      "epoch 10, loss_tr=0.120907 accuracy=0.950234 loss_val=0.105894 accuracy_val=0.666667\n",
      "epoch 11, loss_tr=0.117153 accuracy=0.952383 loss_val=0.135600 accuracy_val=0.833333\n",
      "epoch 12, loss_tr=0.116189 accuracy=0.950625 loss_val=0.084076 accuracy_val=0.833333\n",
      "epoch 13, loss_tr=0.108741 accuracy=0.954687 loss_val=0.150378 accuracy_val=0.500000\n",
      "epoch 14, loss_tr=0.100462 accuracy=0.957852 loss_val=0.093300 accuracy_val=0.833333\n",
      "epoch 15, loss_tr=0.094869 accuracy=0.960391 loss_val=0.028876 accuracy_val=0.666667\n",
      "epoch 16, loss_tr=0.094123 accuracy=0.960664 loss_val=0.065972 accuracy_val=0.666667\n",
      "epoch 17, loss_tr=0.083791 accuracy=0.965977 loss_val=0.079443 accuracy_val=0.666667\n",
      "epoch 18, loss_tr=0.089271 accuracy=0.964180 loss_val=0.063454 accuracy_val=0.833333\n",
      "epoch 19, loss_tr=0.082162 accuracy=0.966016 loss_val=0.115828 accuracy_val=0.833333\n",
      "epoch 20, loss_tr=0.079493 accuracy=0.967656 loss_val=0.112996 accuracy_val=0.833333\n",
      "epoch 21, loss_tr=0.078508 accuracy=0.968008 loss_val=0.070837 accuracy_val=0.500000\n",
      "epoch 22, loss_tr=0.073135 accuracy=0.971328 loss_val=0.104713 accuracy_val=0.833333\n",
      "epoch 23, loss_tr=0.076375 accuracy=0.968320 loss_val=0.027947 accuracy_val=0.333333\n",
      "epoch 24, loss_tr=0.072552 accuracy=0.970937 loss_val=0.079656 accuracy_val=0.833333\n",
      "epoch 25, loss_tr=0.071491 accuracy=0.970469 loss_val=0.033771 accuracy_val=0.833333\n",
      "epoch 26, loss_tr=0.065457 accuracy=0.973906 loss_val=0.053295 accuracy_val=0.833333\n",
      "epoch 27, loss_tr=0.066205 accuracy=0.973242 loss_val=0.069756 accuracy_val=0.666667\n",
      "epoch 28, loss_tr=0.066750 accuracy=0.973477 loss_val=0.035699 accuracy_val=0.333333\n",
      "epoch 29, loss_tr=0.062033 accuracy=0.975430 loss_val=0.042380 accuracy_val=0.833333\n",
      "epoch 30, loss_tr=0.064804 accuracy=0.975000 loss_val=0.048192 accuracy_val=0.666667\n",
      "epoch 31, loss_tr=0.060430 accuracy=0.976680 loss_val=0.078471 accuracy_val=0.833333\n",
      "epoch 32, loss_tr=0.060553 accuracy=0.975820 loss_val=0.065100 accuracy_val=0.833333\n",
      "epoch 33, loss_tr=0.060023 accuracy=0.976172 loss_val=0.122602 accuracy_val=0.833333\n",
      "epoch 34, loss_tr=0.055454 accuracy=0.976953 loss_val=0.068821 accuracy_val=0.833333\n",
      "epoch 35, loss_tr=0.054535 accuracy=0.978672 loss_val=0.073970 accuracy_val=0.833333\n",
      "epoch 36, loss_tr=0.057887 accuracy=0.977305 loss_val=0.021979 accuracy_val=0.833333\n",
      "epoch 37, loss_tr=0.053896 accuracy=0.979258 loss_val=0.046400 accuracy_val=0.833333\n",
      "epoch 38, loss_tr=0.053300 accuracy=0.977383 loss_val=0.061335 accuracy_val=0.833333\n",
      "epoch 39, loss_tr=0.052266 accuracy=0.979727 loss_val=0.025712 accuracy_val=0.666667\n",
      "epoch 40, accuracy_train=0.982031 accuracy_test=0.900000 precision=1.000000 recall=0.800000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "#import scipy.io.wavfile\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import librosa\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import noisereduce as nr\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "parkinson_path = 'audio/spanish/npy/parkinson'\n",
    "healthy_path = 'audio/spanish/npy/healthy_control'\n",
    "labels_path = 'audio/spanish/npy/labels'\n",
    "data_path = 'audio/spanish/npy/audio_list'\n",
    "\n",
    "\n",
    "def create_batches_rnd(batch_size,wlen,fact_amp):\n",
    "    \n",
    " # Initialization of the minibatch (batch_size,[0=>x_t,1=>x_t+N,1=>random_samp])\n",
    "    sig_batch = np.zeros([batch_size, wlen])\n",
    "    lab_batch = np.zeros(batch_size)  \n",
    "    snt_id_arr=np.random.randint(train_len, size=batch_size)\n",
    "    rand_amp_arr = np.random.uniform(1.0-fact_amp,1+fact_amp,batch_size)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        signal = data_train[snt_id_arr[i]]\n",
    "        snt_len = signal.shape[0]\n",
    "        channels = len(signal.shape)\n",
    "        if channels == 2:\n",
    "            print('WARNING: stereo to mono: '+data_folder+wav_lst[snt_id_arr[i]])\n",
    "            signal = signal[:,0]\n",
    "        snt_beg=np.random.randint(snt_len-wlen-1) #randint(0, snt_len-2*wlen-1)\n",
    "        snt_end=snt_beg+wlen\n",
    "        sig_batch[i,:]=signal[snt_beg:snt_end]*rand_amp_arr[i]\n",
    "        lab_batch[i]=labels_train[snt_id_arr[i]]\n",
    "\n",
    "    inp=Variable(torch.from_numpy(sig_batch).float().cuda().contiguous())\n",
    "    lab=Variable(torch.from_numpy(lab_batch).float().cuda().contiguous())\n",
    "  \n",
    "    return inp,lab  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset_type = 'spanish_dataset'\n",
    "\n",
    "\n",
    "with open(healthy_path, 'rb') as f:\n",
    "    healthy_list = pickle.load(f)\n",
    "\n",
    "# Open the file in read-binary mode and load the parkinson_list from the file\n",
    "with open(parkinson_path, 'rb') as f:\n",
    "    healthy_list = pickle.load(f)\n",
    "\n",
    "# Open the file in read-binary mode and load the audio_list from the file\n",
    "with open(data_path, 'rb') as f:\n",
    "    audio_list = pickle.load(f)\n",
    "\n",
    "# Open the file in read-binary mode and load the labels from the file\n",
    "with open(labels_path, 'rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "\n",
    "# Reading cfg file\n",
    "options=read_conf(dataset_type)\n",
    "\n",
    " \n",
    "\n",
    "# Accessing parameters from the options dictionary\n",
    "pt_file = options['pt_file']\n",
    "class_dict_file = options['lab_dict']\n",
    "output_folder=options['output_folder']\n",
    "\n",
    "# [windowing]\n",
    "fs = int(options['fs'])\n",
    "cw_len = int(options['cw_len'])\n",
    "cw_shift = int(options['cw_shift'])\n",
    "\n",
    "# [cnn]\n",
    "cnn_N_filt = list(map(int, options['cnn_N_filt'].split(',')))\n",
    "cnn_len_filt = list(map(int, options['cnn_len_filt'].split(',')))\n",
    "cnn_max_pool_len = list(map(int, options['cnn_max_pool_len'].split(',')))\n",
    "cnn_use_laynorm_inp = str_to_bool(options['cnn_use_laynorm_inp'])\n",
    "cnn_use_batchnorm_inp = str_to_bool(options['cnn_use_batchnorm_inp'])\n",
    "cnn_use_laynorm = list(map(str_to_bool, options['cnn_use_laynorm'].split(',')))\n",
    "cnn_use_batchnorm = list(map(str_to_bool, options['cnn_use_batchnorm'].split(',')))\n",
    "cnn_act = list(map(str, options['cnn_act'].split(',')))\n",
    "cnn_drop = list(map(float, options['cnn_drop'].split(',')))\n",
    "\n",
    "# [dnn]\n",
    "fc_lay = list(map(int, options['fc_lay'].split(',')))\n",
    "fc_drop = list(map(float, options['fc_drop'].split(',')))\n",
    "fc_use_laynorm_inp = str_to_bool(options['fc_use_laynorm_inp'])\n",
    "fc_use_batchnorm_inp = str_to_bool(options['fc_use_batchnorm_inp'])\n",
    "fc_use_batchnorm = list(map(str_to_bool, options['fc_use_batchnorm'].split(',')))\n",
    "fc_use_laynorm = list(map(str_to_bool, options['fc_use_laynorm'].split(',')))\n",
    "fc_act = list(map(str, options['fc_act'].split(',')))\n",
    "\n",
    "# [class]\n",
    "class_lay = list(map(int, options['class_lay'].split(',')))\n",
    "class_drop = list(map(float, options['class_drop'].split(',')))\n",
    "class_use_laynorm_inp = str_to_bool(options['class_use_laynorm_inp'])\n",
    "class_use_batchnorm_inp = str_to_bool(options['class_use_batchnorm_inp'])\n",
    "class_use_batchnorm = list(map(str_to_bool, options['class_use_batchnorm'].split(',')))\n",
    "class_use_laynorm = list(map(str_to_bool, options['class_use_laynorm'].split(',')))\n",
    "class_act = list(map(str, options['class_act'].split(',')))\n",
    "\n",
    "# [optimization]\n",
    "lr = float(options['lr'])\n",
    "batch_size = int(options['batch_size'])\n",
    "N_epochs = 41\n",
    "N_batches = 200\n",
    "N_eval_epoch = int(options['N_eval_epoch'])\n",
    "seed = int(options['seed'])\n",
    "\n",
    "\n",
    "# Folder creation\n",
    "try:\n",
    "    os.stat(output_folder)\n",
    "except:\n",
    "    os.mkdir(output_folder) \n",
    "    \n",
    "    \n",
    "\n",
    "# loss function\n",
    "\n",
    "  \n",
    "# Converting context and shift in samples\n",
    "wlen=int(fs*cw_len/1000.00)\n",
    "wshift=int(fs*cw_shift/1000.00)\n",
    "\n",
    "# Batch_dev\n",
    "Batch_dev=128\n",
    "\n",
    "\n",
    "# Feature extractor CNN\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "cost = nn.NLLLoss()\n",
    "\n",
    "CNN_arch = {'input_dim': wlen,\n",
    "          'fs': fs,\n",
    "          'cnn_N_filt': cnn_N_filt,\n",
    "          'cnn_len_filt': cnn_len_filt,\n",
    "          'cnn_max_pool_len':cnn_max_pool_len,\n",
    "          'cnn_use_laynorm_inp': cnn_use_laynorm_inp,\n",
    "          'cnn_use_batchnorm_inp': cnn_use_batchnorm_inp,\n",
    "          'cnn_use_laynorm':cnn_use_laynorm,\n",
    "          'cnn_use_batchnorm':cnn_use_batchnorm,\n",
    "          'cnn_act': cnn_act,\n",
    "          'cnn_drop':cnn_drop,          \n",
    "          }\n",
    "\n",
    "\n",
    "CNN_net=SincNet(CNN_arch)\n",
    "CNN_net.cuda()\n",
    "\n",
    "\n",
    "DNN1_arch = {'input_dim': CNN_net.out_dim,\n",
    "          'fc_lay': fc_lay,\n",
    "          'fc_drop': fc_drop, \n",
    "          'fc_use_batchnorm': fc_use_batchnorm,\n",
    "          'fc_use_laynorm': fc_use_laynorm,\n",
    "          'fc_use_laynorm_inp': fc_use_laynorm_inp,\n",
    "          'fc_use_batchnorm_inp':fc_use_batchnorm_inp,\n",
    "          'fc_act': fc_act,\n",
    "          }\n",
    "\n",
    "DNN1_net=MLP(DNN1_arch)\n",
    "DNN1_net.cuda()\n",
    "\n",
    "DNN2_arch = {'input_dim':fc_lay[-1] ,\n",
    "          'fc_lay': class_lay,\n",
    "          'fc_drop': class_drop, \n",
    "          'fc_use_batchnorm': class_use_batchnorm,\n",
    "          'fc_use_laynorm': class_use_laynorm,\n",
    "          'fc_use_laynorm_inp': class_use_laynorm_inp,\n",
    "          'fc_use_batchnorm_inp':class_use_batchnorm_inp,\n",
    "          'fc_act': class_act,\n",
    "          }\n",
    "\n",
    "\n",
    "DNN2_net=MLP(DNN2_arch)\n",
    "DNN2_net.cuda()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if pt_file!='none':\n",
    "   checkpoint_load = torch.load(pt_file)\n",
    "   CNN_net.load_state_dict(checkpoint_load['CNN_model_par'])\n",
    "   DNN1_net.load_state_dict(checkpoint_load['DNN1_model_par'])\n",
    "   DNN2_net.load_state_dict(checkpoint_load['DNN2_model_par'])\n",
    "\n",
    "optimizer_CNN = optim.RMSprop(CNN_net.parameters(), lr=lr,alpha=0.95, eps=1e-8) \n",
    "optimizer_DNN1 = optim.RMSprop(DNN1_net.parameters(), lr=lr,alpha=0.95, eps=1e-8) \n",
    "optimizer_DNN2 = optim.RMSprop(DNN2_net.parameters(), lr=lr,alpha=0.95, eps=1e-8) \n",
    "\n",
    "\n",
    "\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(audio_list, labels, test_size=0.25, random_state=42)\n",
    "data_train, data_valid, labels_train, labels_valid = train_test_split(data_train, labels_train, test_size=0.2, random_state=42)\n",
    "history_val_acc= []\n",
    "history_val_loss= []\n",
    "history_train_acc= []\n",
    "history_train_loss= []\n",
    "\n",
    "\n",
    "train_len = len(data_train)\n",
    "test_len  = len(data_test)\n",
    "valid_len = len(data_valid)\n",
    "\n",
    "for epoch in range(N_epochs):\n",
    "  \n",
    "  test_flag=0\n",
    "  CNN_net.train()\n",
    "  DNN1_net.train()\n",
    "  DNN2_net.train()\n",
    "\n",
    "  loss_sum = 0\n",
    "  accuracy_sum = 0\n",
    "  for i in range(N_batches):\n",
    "\n",
    "    [inp,lab]=create_batches_rnd(batch_size,wlen,0.2)\n",
    "    pout=DNN2_net(DNN1_net(CNN_net(inp)))\n",
    "\n",
    "    pred=torch.max(pout,dim=1)[1]\n",
    "    loss = cost(pout, lab.long())\n",
    "    accuracy_train = torch.mean((pred==lab.long()).float())\n",
    "\n",
    "\n",
    "    optimizer_CNN.zero_grad()\n",
    "    optimizer_DNN1.zero_grad() \n",
    "    optimizer_DNN2.zero_grad() \n",
    "\n",
    "    loss.backward()\n",
    "    optimizer_CNN.step()\n",
    "    optimizer_DNN1.step()\n",
    "    optimizer_DNN2.step()\n",
    "\n",
    "    loss_sum=loss_sum + loss.detach()\n",
    "    accuracy_sum=accuracy_sum + accuracy_train.detach()\n",
    "    \n",
    "\n",
    "  loss_tot=loss_sum/N_batches\n",
    "  accuracy_train_res = accuracy_sum/N_batches\n",
    "  history_train_acc.append(accuracy_train_res)\n",
    "  history_train_loss.append(loss_tot)\n",
    "  CNN_net.eval()\n",
    "  DNN1_net.eval()\n",
    "  DNN2_net.eval()\n",
    "  loss_sum = 0\n",
    "  accuracy_val = 0\n",
    "  with torch.no_grad():  \n",
    "    for i in range(valid_len):\n",
    "     signal = torch.from_numpy(data_valid[i]).float().cuda().contiguous()\n",
    "     lab_batch = labels_valid[i]\n",
    "     beg_samp = 0\n",
    "     end_samp=wlen\n",
    "     N_fr=int((signal.shape[0]-wlen)/(wshift))\n",
    "     sig_arr=torch.zeros([Batch_dev,wlen]).float().cuda().contiguous()\n",
    "     lab= Variable((torch.zeros(N_fr+1)+lab_batch).cuda().contiguous().long())\n",
    "     pout=Variable(torch.zeros(N_fr+1,class_lay[-1]).cuda().float().contiguous())\n",
    "     count_fr=0\n",
    "     count_fr_tot=0\n",
    "     while end_samp<signal.shape[0]:\n",
    "         sig_arr[count_fr,:]=signal[beg_samp:end_samp]\n",
    "         beg_samp=beg_samp+wshift\n",
    "         end_samp=beg_samp+wlen\n",
    "         count_fr=count_fr+1\n",
    "         count_fr_tot=count_fr_tot+1\n",
    "         if count_fr==Batch_dev:\n",
    "             inp=Variable(sig_arr)\n",
    "             pout[count_fr_tot-Batch_dev:count_fr_tot,:]=DNN2_net(DNN1_net(CNN_net(inp)))\n",
    "             count_fr=0\n",
    "             sig_arr=torch.zeros([Batch_dev,wlen]).float().cuda().contiguous()\n",
    "    # if count_fr>0:\n",
    "      #inp = Variable(sig_arr[0:count_fr])\n",
    "     # pout[count_fr_tot-count_fr:count_fr_tot,:] = DNN2_net(DNN1_net(CNN_net(inp)))\n",
    "     [val_validation,best_class] = torch.max(torch.sum(pout,dim=0),0)\n",
    "     accuracy_val = accuracy_val + (best_class==lab[0]).float()\n",
    "     loss_sum=loss_sum+loss.detach()\n",
    "        \n",
    "    loss_tot_dev = loss_sum/valid_len \n",
    "    accuracy_val_res = accuracy_val/valid_len\n",
    "    history_val_acc.append(accuracy_val_res)\n",
    "    history_val_loss.append(loss_tot_dev)\n",
    "        \n",
    "# Full Validation  new  \n",
    "  if epoch==N_epochs-1:\n",
    "\n",
    "\n",
    "   test_flag = 1 \n",
    "   loss_sum = 0\n",
    "   true_positives = 0\n",
    "   false_positives = 0\n",
    "   false_negatives = 0\n",
    "   accuracy_te = 0\n",
    "\n",
    "   with torch.no_grad():  \n",
    "\n",
    "    for i in range(test_len):\n",
    "     signal = torch.from_numpy(data_test[i]).float().cuda().contiguous()\n",
    "\n",
    "     lab_batch = labels_test[i]\n",
    "\n",
    "     # split signals into chunks\n",
    "     beg_samp = 0\n",
    "     end_samp=wlen\n",
    "\n",
    "     N_fr=int((signal.shape[0]-wlen)/(wshift))\n",
    "\n",
    "     sig_arr=torch.zeros([Batch_dev,wlen]).float().cuda().contiguous()\n",
    "     lab= Variable((torch.zeros(N_fr+1)+lab_batch).cuda().contiguous().long())\n",
    "     pout=Variable(torch.zeros(N_fr+1,class_lay[-1]).cuda().float().contiguous())\n",
    "     count_fr=0\n",
    "     count_fr_tot=0\n",
    "     while end_samp<signal.shape[0]:\n",
    "         sig_arr[count_fr,:]=signal[beg_samp:end_samp]\n",
    "         beg_samp=beg_samp+wshift\n",
    "         end_samp=beg_samp+wlen\n",
    "         count_fr=count_fr+1\n",
    "         count_fr_tot=count_fr_tot+1\n",
    "         if count_fr==Batch_dev:\n",
    "             inp=Variable(sig_arr)\n",
    "             pout[count_fr_tot-Batch_dev:count_fr_tot,:]=DNN2_net(DNN1_net(CNN_net(inp)))\n",
    "             count_fr=0\n",
    "             sig_arr=torch.zeros([Batch_dev,wlen]).float().cuda().contiguous()\n",
    "            \n",
    "\n",
    "    # if count_fr>0:\n",
    "      #inp = Variable(sig_arr[0:count_fr])\n",
    "     # pout[count_fr_tot-count_fr:count_fr_tot,:] = DNN2_net(DNN1_net(CNN_net(inp)))\n",
    "\n",
    "     [val,best_class] = torch.max(torch.sum(pout,dim=0),0)\n",
    "     accuracy_te = accuracy_te + (best_class==lab[0]).float()\n",
    "     \n",
    "        \n",
    "     loss_sum=loss_sum+loss.detach()\n",
    "     true_positives += ((best_class == 1) & (lab[0] == 1))\n",
    "     false_positives += ((best_class == 1) & (lab[0] == 0))\n",
    "     false_negatives += ((best_class == 0) & (lab[0] == 1))\n",
    "\n",
    "    # Avoid division by zero\n",
    "    precision = true_positives / max(true_positives + false_positives, 1)\n",
    "    recall = true_positives / max(true_positives + false_negatives, 1)\n",
    "    accuracy_te_res = accuracy_te/test_len\n",
    "    \n",
    "\n",
    "\n",
    "   print(\"epoch %i, accuracy_train=%f accuracy_test=%f precision=%f recall=%f\"  % (epoch, accuracy_train_res, accuracy_te_res, precision, recall))\n",
    "\n",
    "\n",
    "   checkpoint={'CNN_model_par': CNN_net.state_dict(),\n",
    "               'DNN1_model_par': DNN1_net.state_dict(),\n",
    "               'DNN2_model_par': DNN2_net.state_dict(),\n",
    "               }\n",
    "   torch.save(checkpoint,output_folder+'/model_raw.pkl')\n",
    "\n",
    "  else:\n",
    "     print(\"epoch %i, loss_tr=%f accuracy=%f loss_val=%f accuracy_val=%f\" % (epoch, loss_tot , accuracy_train_res,loss_tot_dev,accuracy_val_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a19e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29915b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
